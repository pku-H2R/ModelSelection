![Picture](https://github.com/pku-H2R/Model-Selection/blob/master/Picture/machine_learning.png)
# Getting Started 
<p align="center">
 <i>The current landscape of machine learning algorithms: gradient boosting machines for shallow learning problems; and deep learning for perceptual problems.</i> —— Francois Chollet , 《Deep Learning with Python》
</p>
<p align="center">
<i>If you make absolutely no assumption about the data, then there is no reason to prefer one model over any other.</i>
  —— No Free Lunch
</p>
  
# Model List
* [Tree_based_model](#Tree_based_model)
* [Support_Vector_Machine](#Support_Vector_Machine)
* [Logisitc_Regression](#Logistic_Regression)
* [Probabilistic_Graphic_Model](#Probabilistic_Graphic_Model)



# Tree_based_model
  * Pruning  
  * Feature Selection Criteria
    * ID3(Information Gain)
    * C4.5(Information Gain Ratio)
    * CART(Gini Ratio)
  * Ensemble
    * Bagging
      * Random forest
      * Extremely randomized Tree
    * Boosting
      * Adaboost
      * Gradient Boosting Decision Tree(GBDT)
      * Extreme Gradient Boosting Tree(XgBoost)
      * LightGBM
      * CatBoost

# Support_Vector_Machine
  * Classification
      * Binary
        * Hard Margine/Linearly separable SVM(Hard margin maximization)
        * Soft Margine/Linear SVM(Soft margin maximization)
        * Non-linear SVM = (kernel trick & Soft margin maximization)
      * Multi-class
  * Regression
  * Speed up
      * Sequential Minimal Optimization(SMO)
  
 # Logistic_Regression 
 
 # Probabilistic_Graphic_Model
   * Bayesian Network
   * Markov Network
   * Conditional Random Field
  

